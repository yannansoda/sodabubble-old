[[Machine Learning]]

# Full Cycle of a ML project
1. define project 
2. define and collect data
3. train model: training, error analysis & iterative improvement -> loop between 2 and 3 until your model is done
4. deploy in production: deploy, monitor, and maintain system -> back to 3 and/or 2 if needed

# Supervised Learning
## Classification
### linear
- Logistic Regression
- Support Vector Machine SVM: [[Support Vector X#Support Vector Machine SVM]]
### non-linear
- Kernel SVM: [[Support Vector X#Kernels SVM]]
-  [[K-Nearest Neighbor]] (k-NN) 
- [[Naive Bayes]]
- Decision Tree Classification: [[Decision Tree & Random Forest#Decision Tree]]
- Random Forest Classification: [[Decision Tree & Random Forest#Random Forest]]

### Pros and Cons
![](/assets/images/classification-1.png)

## Regression
- Linear Regression
- Polynomial Regression
- Support Vector Regression (SVR) [[Support Vector X#^46e7f9]]
- Decision Tree Regression: [[Decision Tree & Random Forest#Decision Tree]]
- Random Forest Regression: [[Decision Tree & Random Forest#Random Forest]]

### Pros and Cons
![](/assets/images/regression.png)

# Unsupervised Learning
## Clustering
- [[K-Means Clustering]]
- [[Hierarchical Clustering]]

### Pros and Cons
![](/assets/images/clustering.png)

# Association Rule Learning
- Apriori: [[Association Rule Learning#Apriori]]
- Eclat: [[Association Rule Learning#Eclat]]

# Reinforcement learning
- Upper Confidence Bound:  [[Reinforcement learning#Upper Confidence Bound]]
- Thompson Sampling: [[Reinforcement learning#Thompson Sampling]]

# Natural Language Processing

# Deep Learning
- [[Artificial Neural Networks]]
- [[Convolutional Neural Networks]]
- [[Dimensionality Reduction]]:
	- Feature Selection
	- Feature Extraction
		- Principal Component Analysis (PCA)
		- Linear Discriminant Analysis (LDA)
		- Kernel PCA
		- Quadratic Discriminant Analysis (QDA)
- Linear Discriminant Analysis


# Model Selection & Boosting
- k-fold cross validation
	accuracy [[Confusion Matrix#Accuracy]] is used as a standard 
- grid search
	tuning on parameters
- XGBoost (eXtreme Gradient Boosting)
	- 

