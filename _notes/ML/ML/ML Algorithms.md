[[Machine Learning]]
	Table of Contents
```toc 
style: bullet 
min_depth: 1 
max_depth: 6 
```
# Supervised Learning
## Classification
### linear
- Logistic Regression
- Support Vector Machine SVM: [[Support Vector X#Support Vector Machine SVM]]
### non-linear
- Kernel SVM: [[Support Vector X#Kernels SVM]]
-  [[K-Nearest Neighbor]] (k-NN) 
- [[Naive Bayes]]
- Decision Tree Classification: [[Decision Tree & Random Forest#Decision Tree]]
- Random Forest Classification: [[Decision Tree & Random Forest#Random Forest]]

### Pros and Cons
![[Pasted image 20220306124710.png]]

## Regression
- Linear Regression
- Polynomial Regression
- Support Vector Regression (SVR) [[Support Vector X#^46e7f9]]
- Decision Tree Regression: [[Decision Tree & Random Forest#Decision Tree]]
- Random Forest Regression: [[Decision Tree & Random Forest#Random Forest]]

### Pros and Cons
![[Pasted image 20220220114836.png]]

# Unsupervised Learning
## Clustering
- [[K-Means Clustering]]
- [[Hierarchical Clustering]]

### Pros and Cons
![[Pasted image 20220312183704.png]]

# Association Rule Learning
- Apriori: [[Association Rule Learning#Apriori]]
- Eclat: [[Association Rule Learning#Eclat]]

# Reinforcement learning
- Upper Confidence Bound:  [[Reinforcement learning#Upper Confidence Bound]]
- Thompson Sampling: [[Reinforcement learning#Thompson Sampling]]

# Natural Language Processing

# Deep Learning
- [[Artificial Neural Networks]]
- [[Convolutional Neural Networks]]
- [[Dimensionality Reduction]]:
	- Feature Selection
	- Feature Extraction
		- Principal Component Analysis (PCA)
		- Linear Discriminant Analysis (LDA)
		- Kernel PCA
		- Quadratic Discriminant Analysis (QDA)
- Linear Discriminant Analysis


# Model Selection & Boosting
- k-fold cross validation
	accuracy [[Confusion Matrix#Accuracy]] is used as a standard 
- grid search
	tuning on parameters
- XGBoost (eXtreme Gradient Boosting)
	- 